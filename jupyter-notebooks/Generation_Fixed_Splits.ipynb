{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.distributions import Categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fixed Split for Davidson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../data/davidson/annotated_tweets', 'rb') as file_tweets:\n",
    "    annotated_tweets = pickle.load(file_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User</th>\n",
       "      <th>class_0</th>\n",
       "      <th>class_1</th>\n",
       "      <th>class_2</th>\n",
       "      <th>Total</th>\n",
       "      <th>Following</th>\n",
       "      <th>Follower</th>\n",
       "      <th>Network</th>\n",
       "      <th>Category</th>\n",
       "      <th>Category_joined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27511025</td>\n",
       "      <td>3</td>\n",
       "      <td>137</td>\n",
       "      <td>7</td>\n",
       "      <td>147</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1131735763</td>\n",
       "      <td>21</td>\n",
       "      <td>64</td>\n",
       "      <td>48</td>\n",
       "      <td>133</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>229536338</td>\n",
       "      <td>4</td>\n",
       "      <td>117</td>\n",
       "      <td>4</td>\n",
       "      <td>125</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1703531550</td>\n",
       "      <td>5</td>\n",
       "      <td>110</td>\n",
       "      <td>5</td>\n",
       "      <td>120</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200389104</td>\n",
       "      <td>5</td>\n",
       "      <td>93</td>\n",
       "      <td>7</td>\n",
       "      <td>105</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6720</th>\n",
       "      <td>31190263</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6721</th>\n",
       "      <td>218285161</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6722</th>\n",
       "      <td>145063027</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6723</th>\n",
       "      <td>413152043</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6724</th>\n",
       "      <td>331767607</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6725 rows √ó 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            User  class_0  class_1  class_2  Total  Following  Follower  \\\n",
       "0       27511025        3      137        7    147          2         2   \n",
       "1     1131735763       21       64       48    133          1         0   \n",
       "2      229536338        4      117        4    125         11         8   \n",
       "3     1703531550        5      110        5    120          2         7   \n",
       "4      200389104        5       93        7    105          8         5   \n",
       "...          ...      ...      ...      ...    ...        ...       ...   \n",
       "6720    31190263        0        1        0      1          7         4   \n",
       "6721   218285161        0        1        0      1         13        12   \n",
       "6722   145063027        0        1        0      1          2         3   \n",
       "6723   413152043        0        1        0      1          1         0   \n",
       "6724   331767607        0        1        0      1          4         3   \n",
       "\n",
       "      Network  Category  Category_joined  \n",
       "0           1         3                3  \n",
       "1           1         3                3  \n",
       "2           1         3                3  \n",
       "3           1         3                3  \n",
       "4           1         3                3  \n",
       "...       ...       ...              ...  \n",
       "6720        1         1                1  \n",
       "6721        1         1                1  \n",
       "6722        1         1                1  \n",
       "6723        1         1                1  \n",
       "6724        1         1                1  \n",
       "\n",
       "[6725 rows x 10 columns]"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = torch.load('../../data/davidson/User_overview.pt')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_users_to_train_val_test_DAVIDSON(df, splits = [0.6,0.2,0.2]):\n",
    "    splits = torch.tensor(splits)\n",
    "    train_users = []\n",
    "    val_users = []\n",
    "    test_users = []\n",
    "    tweet_distributions = torch.zeros((3,8,3))\n",
    "    for i in range(8):\n",
    "        sub_df = df.loc[df['Category_joined'] == i]\n",
    "        sizer = torch.tensor([len(sub_df)])\n",
    "        sub_df.index = np.arange(sizer.item())\n",
    "        samples = pd.DataFrame(Categorical(splits).sample(sizer)).astype(\"int\")\n",
    "        sub_df = pd.concat([sub_df,samples],axis = 1, join = 'inner')\n",
    "        for user_run in sub_df.iterrows():\n",
    "            if user_run[1][0] == 0:\n",
    "                train_users.append(user_run[1]['User'])\n",
    "                tweet_distributions[0][i][0] += user_run[1]['class_0']\n",
    "                tweet_distributions[0][i][1] += user_run[1]['class_1']\n",
    "                tweet_distributions[0][i][2] += user_run[1]['class_2']\n",
    "            elif user_run[1][0] == 1:\n",
    "                val_users.append(user_run[1]['User'])\n",
    "                tweet_distributions[1][i][0] += user_run[1]['class_0']\n",
    "                tweet_distributions[1][i][1] += user_run[1]['class_1']\n",
    "                tweet_distributions[1][i][2] += user_run[1]['class_2']\n",
    "            else:\n",
    "                test_users.append(user_run[1]['User'])\n",
    "                tweet_distributions[2][i][0] += user_run[1]['class_0']\n",
    "                tweet_distributions[2][i][1] += user_run[1]['class_1']\n",
    "                tweet_distributions[2][i][2] += user_run[1]['class_2']\n",
    "    \n",
    "    return train_users_d, val_users_d, test_users_d, tweet_distributions_d\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_users_d, val_users_d, test_users_d, tweet_distributions_d = assign_users_to_train_val_test(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4046, 1357, 1322)"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_users_d),len(val_users_d),len(test_users_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14939.)"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_distributions_d.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(556.) tensor(125.) tensor(133.)\n",
      "tensor(9423.) tensor(2748.) tensor(2768.)\n"
     ]
    }
   ],
   "source": [
    "check_hate_train = tweet_distributions_d[0][:,0].sum()\n",
    "check_hate_val = tweet_distributions_d[1][:,0].sum()\n",
    "check_hate_test = tweet_distributions_d[2][:,0].sum()\n",
    "check_overall_train = tweet_distributions_d[0,:,:].sum()\n",
    "check_overall_val = tweet_distributions_d[1,:,:].sum()\n",
    "check_overall_test = tweet_distributions_d[2,:,:].sum()\n",
    "print(check_hate_train, check_hate_val, check_hate_test)\n",
    "print(check_overall_train, check_overall_val, check_overall_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  72.,    0.,    0.],\n",
       "         [   0., 2119.,    0.],\n",
       "         [   0.,    0.,  302.],\n",
       "         [ 309., 3119.,  589.],\n",
       "         [  73.,    0.,    0.],\n",
       "         [   0., 1492.,    0.],\n",
       "         [   0.,    0.,  266.],\n",
       "         [ 102.,  673.,  307.]],\n",
       "\n",
       "        [[  19.,    0.,    0.],\n",
       "         [   0.,  709.,    0.],\n",
       "         [   0.,    0.,  121.],\n",
       "         [  42.,  578.,  117.],\n",
       "         [  26.,    0.,    0.],\n",
       "         [   0.,  519.,    0.],\n",
       "         [   0.,    0.,   95.],\n",
       "         [  38.,  376.,  108.]],\n",
       "\n",
       "        [[  17.,    0.,    0.],\n",
       "         [   0.,  747.,    0.],\n",
       "         [   0.,    0.,   61.],\n",
       "         [  43.,  656.,  183.],\n",
       "         [  22.,    0.,    0.],\n",
       "         [   0.,  486.,    0.],\n",
       "         [   0.,    0.,   82.],\n",
       "         [  51.,  326.,   94.]]])"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_distributions_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9789 2550 2600\n"
     ]
    }
   ],
   "source": [
    "# method to generate train, val and test tweets - DAVIDSON\n",
    "\n",
    "tweets = annotated_tweets[\"text\"].values.tolist()\n",
    "labels = annotated_tweets[\"class\"].values.tolist()\n",
    "users = annotated_tweets[\"user\"].values.tolist()\n",
    "users = list(map(int, users))\n",
    "length = len(tweets)\n",
    "train_tweets, train_labels, train_users = [], [], []\n",
    "val_tweets, val_labels, val_users = [], [], []\n",
    "test_tweets, test_labels, test_users = [], [], []\n",
    "\n",
    "\n",
    "s = dict()\n",
    "for i in range(length):\n",
    "    if users[i] in a:\n",
    "        train_tweets.append(tweets[i])\n",
    "        train_labels.append(labels[i])\n",
    "        train_users.append(users[i])\n",
    "    elif users[i] in b:\n",
    "        val_tweets.append(tweets[i])\n",
    "        val_labels.append(labels[i])\n",
    "        val_users.append(users[i])\n",
    "    elif users[i] in c:\n",
    "        test_tweets.append(tweets[i])\n",
    "        test_labels.append(labels[i])\n",
    "        test_users.append(users[i])\n",
    "    else:\n",
    "        train_tweets.append(tweets[i])\n",
    "        train_labels.append(labels[i])\n",
    "        train_users.append(users[i])\n",
    "\n",
    "print(len(train_labels),len(val_labels),len(test_labels))\n",
    "    \n",
    "s[\"train_tweets\"], s[\"train_labels\"], s[\"train_users\"] = train_tweets, train_labels, train_users\n",
    "s[\"val_tweets\"], s[\"val_labels\"], s[\"val_users\"] = val_tweets, val_labels, val_users\n",
    "s[\"test_tweets\"], s[\"test_labels\"], s[\"test_users\"] = test_tweets, test_labels, test_users\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(s, '../../data/davidson/fixed_split.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fixed Splits for Waseem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_tweets_waseem = torch.load('../../data/waseem/annotated_tweets.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>tweet_ids</th>\n",
       "      <th>user_ids</th>\n",
       "      <th>texts</th>\n",
       "      <th>labels_num</th>\n",
       "      <th>texts_preprocessed_ekphrasis</th>\n",
       "      <th>texts_preprocessed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>racism</td>\n",
       "      <td>572342978255048705</td>\n",
       "      <td>2498963143</td>\n",
       "      <td>So Drasko just said he was impressed the girls...</td>\n",
       "      <td>1</td>\n",
       "      <td>[so, drasko, just, said, he, was, impressed, t...</td>\n",
       "      <td>[drasko, -PRON-, impressed, girl, cook, half, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>racism</td>\n",
       "      <td>572341498827522049</td>\n",
       "      <td>110114783</td>\n",
       "      <td>Drasko they didn't cook half a bird you idiot ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[drasko, they, did, not, cook, half, a, bird, ...</td>\n",
       "      <td>[drasko, -PRON-, cook, half, bird, -PRON-, idi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>racism</td>\n",
       "      <td>572340476503724032</td>\n",
       "      <td>38650214</td>\n",
       "      <td>Hopefully someone cooks Drasko in the next ep ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[hopefully, someone, cooks, drasko, in, the, n...</td>\n",
       "      <td>[hopefully, cook, drasko, ep, hashtag, mkr, ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>racism</td>\n",
       "      <td>572334712804384768</td>\n",
       "      <td>2587278392</td>\n",
       "      <td>of course you were born in serbia...you're as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[of, course, you, were, born, in, serbia, ., &lt;...</td>\n",
       "      <td>[course, -PRON-, bear, serbia, repeat, -PRON-,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>racism</td>\n",
       "      <td>572332655397629952</td>\n",
       "      <td>2601524623</td>\n",
       "      <td>These girls are the equivalent of the irritati...</td>\n",
       "      <td>1</td>\n",
       "      <td>[these, girls, are, the, equivalent, of, the, ...</td>\n",
       "      <td>[girl, equivalent, irritate, asian, girl, coup...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16902</th>\n",
       "      <td>none</td>\n",
       "      <td>576359685843861505</td>\n",
       "      <td>2941145694</td>\n",
       "      <td>RT @JakeM_1998: RT BillSpindle: It's all about...</td>\n",
       "      <td>2</td>\n",
       "      <td>[rt, &lt;user&gt;, :, rt, billspindle, :, it, ', s, ...</td>\n",
       "      <td>[rt, user, rt, billspindle, -PRON-, ', s, powe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16903</th>\n",
       "      <td>none</td>\n",
       "      <td>576612926838046720</td>\n",
       "      <td>2941145694</td>\n",
       "      <td>RT @ThinkAgain_DOS: Iraq: #ISIS sets off 21 ca...</td>\n",
       "      <td>2</td>\n",
       "      <td>[rt, &lt;user&gt;, :, iraq, :, &lt;hashtag&gt;, isis, &lt;/ha...</td>\n",
       "      <td>[rt, user, iraq, hashtag, isis, hashtag, set, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16904</th>\n",
       "      <td>none</td>\n",
       "      <td>576771329975664640</td>\n",
       "      <td>2941145694</td>\n",
       "      <td>RT @ThePatriot143: DEAR STATE DEPARTMENT: WHER...</td>\n",
       "      <td>2</td>\n",
       "      <td>[rt, &lt;user&gt;, :, &lt;allcaps&gt;, dear, state, depart...</td>\n",
       "      <td>[rt, user, allcaps, dear, state, department, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16905</th>\n",
       "      <td>none</td>\n",
       "      <td>560595245814267905</td>\n",
       "      <td>2756873076</td>\n",
       "      <td>\"@panelrific: Let's go üêßüêßüêßüêßüêßüêßüòÉ\"</td>\n",
       "      <td>2</td>\n",
       "      <td>[\", &lt;user&gt;, :, let, us, go, üêß, üêß, üêß, üêß, üêß, üêß, ...</td>\n",
       "      <td>[ , user, let, -PRON-]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16906</th>\n",
       "      <td>none</td>\n",
       "      <td>569363477095174145</td>\n",
       "      <td>2756873076</td>\n",
       "      <td>RT @TheMeninism: üòÇ http://t.co/VQzuAXqNzd</td>\n",
       "      <td>2</td>\n",
       "      <td>[rt, &lt;user&gt;, :, üòÇ, &lt;url&gt;]</td>\n",
       "      <td>[rt, user, url]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16907 rows √ó 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       labels           tweet_ids    user_ids  \\\n",
       "0      racism  572342978255048705  2498963143   \n",
       "1      racism  572341498827522049   110114783   \n",
       "2      racism  572340476503724032    38650214   \n",
       "3      racism  572334712804384768  2587278392   \n",
       "4      racism  572332655397629952  2601524623   \n",
       "...       ...                 ...         ...   \n",
       "16902    none  576359685843861505  2941145694   \n",
       "16903    none  576612926838046720  2941145694   \n",
       "16904    none  576771329975664640  2941145694   \n",
       "16905    none  560595245814267905  2756873076   \n",
       "16906    none  569363477095174145  2756873076   \n",
       "\n",
       "                                                   texts  labels_num  \\\n",
       "0      So Drasko just said he was impressed the girls...           1   \n",
       "1      Drasko they didn't cook half a bird you idiot ...           1   \n",
       "2      Hopefully someone cooks Drasko in the next ep ...           1   \n",
       "3      of course you were born in serbia...you're as ...           1   \n",
       "4      These girls are the equivalent of the irritati...           1   \n",
       "...                                                  ...         ...   \n",
       "16902  RT @JakeM_1998: RT BillSpindle: It's all about...           2   \n",
       "16903  RT @ThinkAgain_DOS: Iraq: #ISIS sets off 21 ca...           2   \n",
       "16904  RT @ThePatriot143: DEAR STATE DEPARTMENT: WHER...           2   \n",
       "16905                    \"@panelrific: Let's go üêßüêßüêßüêßüêßüêßüòÉ\"           2   \n",
       "16906          RT @TheMeninism: üòÇ http://t.co/VQzuAXqNzd           2   \n",
       "\n",
       "                            texts_preprocessed_ekphrasis  \\\n",
       "0      [so, drasko, just, said, he, was, impressed, t...   \n",
       "1      [drasko, they, did, not, cook, half, a, bird, ...   \n",
       "2      [hopefully, someone, cooks, drasko, in, the, n...   \n",
       "3      [of, course, you, were, born, in, serbia, ., <...   \n",
       "4      [these, girls, are, the, equivalent, of, the, ...   \n",
       "...                                                  ...   \n",
       "16902  [rt, <user>, :, rt, billspindle, :, it, ', s, ...   \n",
       "16903  [rt, <user>, :, iraq, :, <hashtag>, isis, </ha...   \n",
       "16904  [rt, <user>, :, <allcaps>, dear, state, depart...   \n",
       "16905  [\", <user>, :, let, us, go, üêß, üêß, üêß, üêß, üêß, üêß, ...   \n",
       "16906                          [rt, <user>, :, üòÇ, <url>]   \n",
       "\n",
       "                                      texts_preprocessed  \n",
       "0      [drasko, -PRON-, impressed, girl, cook, half, ...  \n",
       "1      [drasko, -PRON-, cook, half, bird, -PRON-, idi...  \n",
       "2      [hopefully, cook, drasko, ep, hashtag, mkr, ha...  \n",
       "3      [course, -PRON-, bear, serbia, repeat, -PRON-,...  \n",
       "4      [girl, equivalent, irritate, asian, girl, coup...  \n",
       "...                                                  ...  \n",
       "16902  [rt, user, rt, billspindle, -PRON-, ', s, powe...  \n",
       "16903  [rt, user, iraq, hashtag, isis, hashtag, set, ...  \n",
       "16904  [rt, user, allcaps, dear, state, department, a...  \n",
       "16905                             [ , user, let, -PRON-]  \n",
       "16906                                    [rt, user, url]  \n",
       "\n",
       "[16907 rows x 7 columns]"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotated_tweets_waseem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User</th>\n",
       "      <th>class_0</th>\n",
       "      <th>class_1</th>\n",
       "      <th>class_2</th>\n",
       "      <th>Total</th>\n",
       "      <th>Following</th>\n",
       "      <th>Follower</th>\n",
       "      <th>Network</th>\n",
       "      <th>Category</th>\n",
       "      <th>Category_joined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2941145694</td>\n",
       "      <td>51</td>\n",
       "      <td>1952</td>\n",
       "      <td>2543</td>\n",
       "      <td>4546</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13857342</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3853</td>\n",
       "      <td>3854</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>930620467</td>\n",
       "      <td>1371</td>\n",
       "      <td>8</td>\n",
       "      <td>969</td>\n",
       "      <td>2348</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2756873076</td>\n",
       "      <td>1029</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "      <td>1127</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>545159350</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>51</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>428909910</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>20301438</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>191741196</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>26354418</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023</th>\n",
       "      <td>990582259</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2024 rows √ó 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            User  class_0  class_1  class_2  Total  Following  Follower  \\\n",
       "0     2941145694       51     1952     2543   4546          0         0   \n",
       "1       13857342        1        0     3853   3854          0         1   \n",
       "2      930620467     1371        8      969   2348          0         3   \n",
       "3     2756873076     1029        0       98   1127          5         3   \n",
       "4      545159350        4        0       47     51          4         7   \n",
       "...          ...      ...      ...      ...    ...        ...       ...   \n",
       "2019   428909910        0        0        1      1          0         0   \n",
       "2020    20301438        0        0        1      1          0         0   \n",
       "2021   191741196        0        0        1      1          3         0   \n",
       "2022    26354418        0        0        1      1          4         4   \n",
       "2023   990582259        0        0        1      1          0         0   \n",
       "\n",
       "      Network  Category  Category_joined  \n",
       "0           0         6                6  \n",
       "1           0         6                6  \n",
       "2           1         6                6  \n",
       "3           0         6                6  \n",
       "4           1         2                2  \n",
       "...       ...       ...              ...  \n",
       "2019        0         1                4  \n",
       "2020        0         1                4  \n",
       "2021        1         1                1  \n",
       "2022        1         1                1  \n",
       "2023        0         1                4  \n",
       "\n",
       "[2024 rows x 10 columns]"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_waseem = torch.load('../../data/waseem/User_overview.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_users_to_train_val_test_WASEEM(df, splits = [0.6,0.2,0.2]):\n",
    "    '''Difference to Davidson method: do not split category 6, this will be handled separately'''\n",
    "    splits = torch.tensor(splits)\n",
    "    train_users = []\n",
    "    val_users = []\n",
    "    test_users = []\n",
    "    tweet_distributions = torch.zeros((3,6,3))\n",
    "    for i in range(6):\n",
    "        sub_df = df.loc[df['Category_joined'] == i]\n",
    "        sizer = torch.tensor([len(sub_df)])\n",
    "        sub_df.index = np.arange(sizer.item())\n",
    "        samples = pd.DataFrame(Categorical(splits).sample(sizer)).astype(\"int\")\n",
    "        sub_df = pd.concat([sub_df,samples],axis = 1, join = 'inner')\n",
    "        for user_run in sub_df.iterrows():\n",
    "            if user_run[1][0] == 0:\n",
    "                train_users.append(user_run[1]['User'])\n",
    "                tweet_distributions[0][i][0] += user_run[1]['class_0']\n",
    "                tweet_distributions[0][i][1] += user_run[1]['class_1']\n",
    "                tweet_distributions[0][i][2] += user_run[1]['class_2']\n",
    "            elif user_run[1][0] == 1:\n",
    "                val_users.append(user_run[1]['User'])\n",
    "                tweet_distributions[1][i][0] += user_run[1]['class_0']\n",
    "                tweet_distributions[1][i][1] += user_run[1]['class_1']\n",
    "                tweet_distributions[1][i][2] += user_run[1]['class_2']\n",
    "            else:\n",
    "                test_users.append(user_run[1]['User'])\n",
    "                tweet_distributions[2][i][0] += user_run[1]['class_0']\n",
    "                tweet_distributions[2][i][1] += user_run[1]['class_1']\n",
    "                tweet_distributions[2][i][2] += user_run[1]['class_2']\n",
    "    \n",
    "    return train_users, val_users, test_users, tweet_distributions\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_users_w, val_users_w, test_users_w, tweet_distributions_w = assign_users_to_train_val_test_WASEEM(df_waseem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1180 424 416 2020\n"
     ]
    }
   ],
   "source": [
    "print(len(train_users_w),len(val_users_w),len(test_users_w), sum((len(train_users_w),len(val_users_w),len(test_users_w))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5032.)"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_distributions_w.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10166 3424 3317\n"
     ]
    }
   ],
   "source": [
    "# method to generate train, val and test tweets - Waseem\n",
    "splits = torch.tensor([0.6,0.2,0.2])\n",
    "tweets = annotated_tweets_waseem[\"texts\"].values.tolist()\n",
    "labels = annotated_tweets_waseem[\"labels_num\"].values.tolist()\n",
    "users = annotated_tweets_waseem[\"user_ids\"].values.tolist()\n",
    "users = list(map(int, users))\n",
    "length = len(tweets)\n",
    "train_tweets, train_labels, train_users = [], [], []\n",
    "val_tweets, val_labels, val_users = [], [], []\n",
    "test_tweets, test_labels, test_users = [], [], []\n",
    "count_4users = 0\n",
    "\n",
    "waseem_dict = dict()\n",
    "for i in range(length):\n",
    "    if users[i] in train_users_w:\n",
    "        train_tweets.append(tweets[i])\n",
    "        train_labels.append(labels[i])\n",
    "        train_users.append(users[i])\n",
    "    elif users[i] in val_users_w:\n",
    "        val_tweets.append(tweets[i])\n",
    "        val_labels.append(labels[i])\n",
    "        val_users.append(users[i])\n",
    "    elif users[i] in test_users_w:\n",
    "        test_tweets.append(tweets[i])\n",
    "        test_labels.append(labels[i])\n",
    "        test_users.append(users[i])\n",
    "    else :\n",
    "        category = Categorical(splits).sample().item()\n",
    "        #print(category)\n",
    "        count_4users += 1\n",
    "        if category == 0:\n",
    "            train_tweets.append(tweets[i])\n",
    "            train_labels.append(labels[i])\n",
    "            train_users.append(users[i])\n",
    "        elif category == 1:\n",
    "            val_tweets.append(tweets[i])\n",
    "            val_labels.append(labels[i])\n",
    "            val_users.append(users[i])\n",
    "        else: \n",
    "            test_tweets.append(tweets[i])\n",
    "            test_labels.append(labels[i])\n",
    "            test_users.append(users[i])\n",
    "\n",
    "print(len(train_labels),len(val_labels),len(test_labels))\n",
    "    \n",
    "waseem_dict[\"train_tweets\"], waseem_dict[\"train_labels\"], waseem_dict[\"train_users\"] = train_tweets, train_labels, train_users\n",
    "waseem_dict[\"val_tweets\"], waseem_dict[\"val_labels\"], waseem_dict[\"val_users\"] = val_tweets, val_labels, val_users\n",
    "waseem_dict[\"test_tweets\"], waseem_dict[\"test_labels\"], waseem_dict[\"test_users\"] = test_tweets, test_labels, test_users\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(waseem_dict, '../../data/waseem/fixed_split.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11875"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_4users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  2049 1188 6929\n",
      "Val:  699 385 2340\n",
      "Test:  682 403 2232\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", train_labels.count(0),train_labels.count(1),train_labels.count(2))\n",
    "print(\"Val: \", val_labels.count(0),val_labels.count(1),val_labels.count(2))\n",
    "print(\"Test: \", test_labels.count(0), test_labels.count(1), test_labels.count(2))\n",
    "#len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
